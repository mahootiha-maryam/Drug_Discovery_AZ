{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all of the smiles and then try to choose 70 percent for training, 10 percent for validation and 20 percent for test set. Making positive pairs and negative pairs for train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "from rdkit import RDLogger\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_file ='/home/kvvq085/datasets/chembl/chembl_34_chemreps.txt' \n",
    "with open(smiles_file, 'r') as file:\n",
    "        # Read header line and find index of canonical_smiles column\n",
    "        header = file.readline().strip().split('\\t')\n",
    "        smiles_col_idx = header.index('canonical_smiles')\n",
    "        smiles_list = [line.strip().split('\\t')[smiles_col_idx] for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_logger = RDLogger.logger()\n",
    "rd_logger.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(121274)\n",
    "\n",
    "# Generate random indices for splitting\n",
    "indices = np.random.permutation(len(smiles_list))\n",
    "\n",
    "# Calculate split points\n",
    "train_size = int(0.7 * len(smiles_list))\n",
    "val_size = int(0.1 * len(smiles_list))\n",
    "\n",
    "# Split indices\n",
    "train_idx = indices[:train_size].tolist()\n",
    "val_idx = indices[train_size:train_size+val_size].tolist()\n",
    "test_idx = indices[train_size+val_size:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [smiles_list[i] for i in train_idx]\n",
    "X_val = [smiles_list[i] for i in val_idx]\n",
    "X_test = [smiles_list[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding if each molecule has a substructure based on reactant 1 and reactant 2. If it has the substructure make pattern True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 56 approved rules.\n"
     ]
    }
   ],
   "source": [
    "def parse_smiles(smiles_list):\n",
    "    return [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "\n",
    "# Step 1: Read and parse approved rules\n",
    "def load_approved_rules(file_path):\n",
    "    approved_rules = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            rule = line.strip()\n",
    "            try:\n",
    "                reactant_smarts, product_smarts = rule.split(\">>\")\n",
    "                smarts_1, smarts_2 = reactant_smarts.split(\".\")\n",
    "                query1 = Chem.MolFromSmarts(smarts_1)\n",
    "                query2 = Chem.MolFromSmarts(smarts_2)\n",
    "                if query1 is not None and query2 is not None:\n",
    "                    approved_rules.append({\n",
    "                        'rule': rule,\n",
    "                        'query1': query1,\n",
    "                        'query2': query2\n",
    "                    })\n",
    "            except ValueError:\n",
    "                # Log or handle improperly formatted rules if necessary\n",
    "                continue\n",
    "    return approved_rules\n",
    "\n",
    "# Step 2: Pre-parse all molecules\n",
    "def preprocess_molecules(X_train, X_val, X_test):\n",
    "    data = {}\n",
    "    data['train_smiles'] = X_train\n",
    "    data['val_smiles'] = X_val\n",
    "    data['test_smiles'] = X_test\n",
    "    data['train_mols'] = parse_smiles(X_train)\n",
    "    data['val_mols'] = parse_smiles(X_val)\n",
    "    data['test_mols'] = parse_smiles(X_test)\n",
    "    return data\n",
    "\n",
    "# Step 3: Process rules and collect data\n",
    "def process_rules(approved_rules, data):\n",
    "    # Initialize lists to collect data\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for rule in tqdm(approved_rules, desc=\"Processing Rules\"):\n",
    "        rule_str = rule['rule']\n",
    "        query1 = rule['query1']\n",
    "        query2 = rule['query2']\n",
    "        \n",
    "        # Process training set\n",
    "        for smiles, mol in zip(data['train_smiles'], data['train_mols']):\n",
    "            if mol is None:\n",
    "                continue\n",
    "            match1 = mol.HasSubstructMatch(query1)\n",
    "            match2 = mol.HasSubstructMatch(query2)\n",
    "            train_data.append((smiles, match1, match2, rule_str))\n",
    "        \n",
    "        # Process validation set\n",
    "        for smiles, mol in zip(data['val_smiles'], data['val_mols']):\n",
    "            if mol is None:\n",
    "                continue\n",
    "            match1 = mol.HasSubstructMatch(query1)\n",
    "            match2 = mol.HasSubstructMatch(query2)\n",
    "            val_data.append((smiles, match1, match2, rule_str))\n",
    "        \n",
    "        # Process test set\n",
    "        for smiles, mol in zip(data['test_smiles'], data['test_mols']):\n",
    "            if mol is None:\n",
    "                continue\n",
    "            match1 = mol.HasSubstructMatch(query1)\n",
    "            match2 = mol.HasSubstructMatch(query2)\n",
    "            test_data.append((smiles, match1, match2, rule_str))\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Step 4: Convert collected data into DataFrames\n",
    "def create_dataframes(train_data, val_data, test_data):\n",
    "    df_train = pd.DataFrame(train_data, columns=['molecule', 'pattern_1', 'pattern_2', 'rule'])\n",
    "    df_val = pd.DataFrame(val_data, columns=['molecule', 'pattern_1', 'pattern_2', 'rule'])\n",
    "    df_test = pd.DataFrame(test_data, columns=['molecule', 'pattern_1', 'pattern_2', 'rule'])\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "# Main Execution Flow\n",
    "\n",
    "\n",
    "    # Load approved rules\n",
    "approved_rules = load_approved_rules('hb_edited.txt')\n",
    "print(f\"Loaded {len(approved_rules)} approved rules.\")\n",
    "\n",
    "# Preprocess molecules\n",
    "data = preprocess_molecules(X_train, X_val, X_test)\n",
    "print(\"Pre-parsed all molecule SMILES.\")\n",
    "\n",
    "# Process rules and collect matching data\n",
    "train_data, val_data, test_data = process_rules(approved_rules, data)\n",
    "print(\"Completed processing all rules.\")\n",
    "\n",
    "# Create DataFrames\n",
    "df_train, df_val, df_test = create_dataframes(train_data, val_data, test_data)\n",
    "print(\"DataFrames created successfully.\")\n",
    "\n",
    "# Optional: Save DataFrames to CSV\n",
    "# df_train.to_csv('df_train.csv', index=False)\n",
    "# df_val.to_csv('df_val.csv', index=False)\n",
    "# df_test.to_csv('df_test.csv', index=False)\n",
    "\n",
    "# For demonstration, print first few rows\n",
    "print(\"Training DataFrame:\")\n",
    "print(df_train.head())\n",
    "print(\"\\nValidation DataFrame:\")\n",
    "print(df_val.head())\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"pattern_matching_training.csv\")\n",
    "df_val.to_csv(\"pattern_matching_val.csv\")\n",
    "df_test.to_csv(\"pattern_matching_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94443272"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13491912"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26983768"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717499 778688\n"
     ]
    }
   ],
   "source": [
    "print(sum(df_test['pattern_2'] == True), sum(df_test['pattern_1'] == True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making positive and negative pairs for train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_matching_train = pd.read_csv(\"pattern_matching_training.csv\")\n",
    "pattern_matching_val = pd.read_csv(\"pattern_matching_val.csv\")\n",
    "pattern_matching_test = pd.read_csv(\"pattern_matching_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating possible pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Pairs: 100%|██████████| 56/56 [00:37<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible pairs across all rules: 282092928544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 121274\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Desired maximum number of positive pairs\n",
    "MAX_PAIRS = 1000000\n",
    "\n",
    "# Group by 'rule'\n",
    "grouped_rules = pattern_matching_train.groupby('rule')\n",
    "\n",
    "# Step 1: Calculate total possible pairs and per-rule pair counts\n",
    "total_possible = 0\n",
    "rule_pair_counts = {}\n",
    "\n",
    "# First pass: compute possible pairs per rule\n",
    "print(\"Calculating possible pairs per rule...\")\n",
    "for rule, group in tqdm(grouped_rules, desc=\"Calculating Pairs\"):\n",
    "    pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "    pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "    num_p = len(pattern1_molecules) * len(pattern2_molecules)\n",
    "    rule_pair_counts[rule] = num_p\n",
    "    total_possible += num_p\n",
    "\n",
    "print(f\"Total possible pairs across all rules: {total_possible}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing positive_pairs and negative_pairs based on **sample_fraction**\n",
    "\n",
    "Sampling Fraction is a number between 0 and 1 that determines what portion of the total possible pairs you will keep. Here's how it works:\n",
    "\n",
    "Calculate Total Possible Pairs: First, find out how many pairs each rule can generate and add them all up.\n",
    "\n",
    "Small Rules: If a rule generates very few pairs, it might contribute fewer than expected. The code ensures that at least one pair is sampled if possible, preventing rules from being entirely excluded.\n",
    "\n",
    "For Example:\n",
    "\n",
    "Rule A can generate 500,000 pairs\n",
    "\n",
    "Rule B can generate 1,500,000 pairs\n",
    "\n",
    "Total Possible Pairs = 500,000 + 1,500,000 = 2,000,000 pairs\n",
    "\n",
    "Determine Sampling Fraction: Want to reduce the total from 2,000,000 pairs to 1,000,000 pairs.\n",
    "\n",
    "Sampling Fraction = Desired Total Pairs / Total Possible Pairs\n",
    "\n",
    "Sampling Fraction = 1,000,000 / 2,000,000 = 0.5\n",
    "\n",
    "This means you'll keep 50% of the pairs from each rule.\n",
    "\n",
    "Rule A:\n",
    "\n",
    "Possible Pairs: 500,000\n",
    "\n",
    "Pairs to Sample: 500,000 * 0.5 = 250,000\n",
    "\n",
    "Rule B:\n",
    "\n",
    "Possible Pairs: 1,500,000\n",
    "\n",
    "Pairs to Sample: 1,500,000 * 0.5 = 750,000\n",
    "\n",
    "Total Sampled Pairs: 250,000 (Rule A) + 750,000 (Rule B) = 1,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling fraction: 0.000004\n",
      "Total sampled pairs after adjustment: 999985\n",
      "Sampling pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Pairs: 100%|██████████| 56/56 [00:24<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 999985 sampled positive pairs.\n",
      "Final number of positive pairs: 999985\n",
      "                                                mol1  \\\n",
      "0         CCOC(=O)c1c(SC)c(C#N)c(-c2ccc(Br)cc2)oc1=O   \n",
      "1      C#CCOc1ccc(CCNC(=O)C(OCC#C)c2ccc(Cl)cc2)cc1OC   \n",
      "2  CCOC(=O)N[C@@H](c1cccnc1)[C@@H](O)C(=O)OC1CC2C...   \n",
      "3                   CN(C)CCC#CC(O)(c1ccccc1)c1ccccc1   \n",
      "4  N#Cc1ccc(N2C(=O)C3(CC3)N(c3ccc4c(c3)COC4=O)C2=...   \n",
      "\n",
      "                                                mol2  \\\n",
      "0  CC(=O)O[C@H]1C[C@@](C)(C(=O)O)C[C@H]2C3=CC(=O)...   \n",
      "1  CC(CO)/N=C(\\N)c1c(O)nsc1Nc1ccc(Oc2cc(F)cc(F)c2...   \n",
      "2      CC(NC(=O)CCn1nc(-c2ccc(Cl)cc2)ccc1=O)c1ccccc1   \n",
      "3  NC(=O)[C@@]12C[C@@H]1[C@@H](n1cnc3c(N)nc(Cl)nc...   \n",
      "4  O=C(O)c1ccc(Cl)cc1-c1ccc(/C=C2\\C(=O)N(c3ccccc3...   \n",
      "\n",
      "                                                rule  \n",
      "0  [#6:6][C:5]#[#7;D1:4].[#6:1][C:2](=[OD1:3])[OH...  \n",
      "1  [CH0;$(C-[#6]):1]#[CH1:2].[C;H1,H2;A;!$(C=O):3...  \n",
      "2  [C$([C](O)([CX4])([CX4])([CX4])),C$([CH](O)([C...  \n",
      "3  [CH0;$(C-[#6]):1]#[CH0;$(C-[#6]):2].[C;H1,H2;A...  \n",
      "4  [#6:6][C:5]#[#7;D1:4].[#6:1][C:2](=[OD1:3])[OH...  \n"
     ]
    }
   ],
   "source": [
    "# If total_possible is less than MAX_PAIRS, proceed without sampling\n",
    "if total_possible <= MAX_PAIRS:\n",
    "    positive_pairs = []\n",
    "\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Generating All Pairs\"):\n",
    "        pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "        pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "\n",
    "        # Create all possible pairs using cross join\n",
    "        pairs = pd.MultiIndex.from_product(\n",
    "            [pattern1_molecules, pattern2_molecules],\n",
    "            names=['mol1', 'mol2']\n",
    "        ).to_frame(index=False)\n",
    "\n",
    "        # Add 'rule' column\n",
    "        pairs['rule'] = rule\n",
    "\n",
    "        # Append to positive_pairs\n",
    "        positive_pairs.append(pairs)\n",
    "\n",
    "    # Concatenate all pairs into a single DataFrame\n",
    "    positive_pairs_df = pd.concat(positive_pairs, ignore_index=True)\n",
    "    print(f\"Generated {len(positive_pairs_df)} positive pairs.\")\n",
    "else:\n",
    "    # Need to sample pairs to limit total number to MAX_PAIRS\n",
    "    positive_pairs = []\n",
    "\n",
    "    # Calculate sampling fraction\n",
    "    sampling_fraction = MAX_PAIRS / total_possible\n",
    "    print(f\"Sampling fraction: {sampling_fraction:.6f}\")\n",
    "\n",
    "    # Calculate the number of pairs to sample per rule\n",
    "    sampled_pairs_per_rule = {}\n",
    "    for rule, count in rule_pair_counts.items():\n",
    "        sampled_pairs = int(count * sampling_fraction)\n",
    "        # Ensure at least one pair is sampled if possible\n",
    "        if sampled_pairs < 1 and count > 0:\n",
    "            sampled_pairs = 1\n",
    "        sampled_pairs_per_rule[rule] = sampled_pairs\n",
    "\n",
    "    # Adjust total sampled pairs if sum exceeds MAX_PAIRS\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    if total_sampled > MAX_PAIRS:\n",
    "        # Reduce the number of pairs proportionally\n",
    "        scaling_factor = MAX_PAIRS / total_sampled\n",
    "        for rule in sampled_pairs_per_rule:\n",
    "            sampled_pairs_per_rule[rule] = int(sampled_pairs_per_rule[rule] * scaling_factor)\n",
    "    \n",
    "    # Recalculate total sampled pairs after adjustment\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    print(f\"Total sampled pairs after adjustment: {total_sampled}\")\n",
    "\n",
    "    # Second pass: sample pairs per rule\n",
    "    print(\"Sampling pairs per rule...\")\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Sampling Pairs\"):\n",
    "        num_to_sample = sampled_pairs_per_rule.get(rule, 0)\n",
    "        if num_to_sample == 0:\n",
    "            continue\n",
    "\n",
    "        pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "        pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "\n",
    "        n1 = len(pattern1_molecules)\n",
    "        n2 = len(pattern2_molecules)\n",
    "\n",
    "        if n1 == 0 or n2 == 0:\n",
    "            continue  # No possible pairs for this rule\n",
    "\n",
    "        # If the number of possible pairs is less than or equal to num_to_sample, take all\n",
    "        if n1 * n2 <= num_to_sample:\n",
    "            sampled_mol1 = np.repeat(pattern1_molecules, n2)\n",
    "            sampled_mol2 = np.tile(pattern2_molecules, n1)\n",
    "        else:\n",
    "            # Randomly sample with replacement=False if possible\n",
    "            # To sample unique pairs without replacement, we can sample indices\n",
    "            sampled_indices_mol1 = np.random.choice(n1, size=num_to_sample, replace=True)\n",
    "            sampled_indices_mol2 = np.random.choice(n2, size=num_to_sample, replace=True)\n",
    "            sampled_mol1 = pattern1_molecules[sampled_indices_mol1]\n",
    "            sampled_mol2 = pattern2_molecules[sampled_indices_mol2]\n",
    "\n",
    "        # Create a DataFrame of sampled pairs\n",
    "        sampled_df = pd.DataFrame({\n",
    "            'molecule': sampled_mol1,\n",
    "            'paired_molecule': sampled_mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        # Append to positive_pairs\n",
    "        positive_pairs.append(sampled_df)\n",
    "\n",
    "    # Concatenate all sampled pairs into a single DataFrame\n",
    "    positive_pairs_df = pd.concat(positive_pairs, ignore_index=True)\n",
    "    # Rename columns for consistency\n",
    "    positive_pairs_df.rename(columns={'molecule': 'mol1', 'paired_molecule': 'mol2'}, inplace=True)\n",
    "    print(f\"Generated {len(positive_pairs_df)} sampled positive pairs.\")\n",
    "\n",
    "# Optional: Shuffle the positive_pairs_df\n",
    "positive_pairs_df = positive_pairs_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# Limit to MAX_PAIRS if necessary\n",
    "if len(positive_pairs_df) > MAX_PAIRS:\n",
    "    positive_pairs_df = positive_pairs_df.iloc[:MAX_PAIRS]\n",
    "\n",
    "print(f\"Final number of positive pairs: {len(positive_pairs_df)}\")\n",
    "\n",
    "# Display a preview\n",
    "print(positive_pairs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs_df.to_csv(\"pos_pairs_train_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating possible negative pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Pairs: 100%|██████████| 56/56 [00:47<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible negative pairs across all rules: 133,014,814,709,442\n",
      "Total possible pairs exceed the desired maximum. Sampling required...\n",
      "Sampling fraction: 0.000000\n",
      "Total sampled pairs after adjustment: 999,974\n",
      "Sampling negative pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Pairs: 100%|██████████| 56/56 [00:37<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 999,974 sampled negative pairs.\n",
      "Final number of negative pairs: 999,974\n",
      "                                                mol1  \\\n",
      "0     CC(=O)O.Nc1nc(N)c2cc(CNc3cccc(Cl)c3)ccc2n1.O.O   \n",
      "1                  CCCCc1ccc2nc(NC(=O)c3sccc3C)sc2c1   \n",
      "2  Cc1c(C(=O)NCCC(C)C)sc2ncnc(Oc3ccc(NC(=O)C4(C(=...   \n",
      "3         COc1cc(-c2cn(-c3c(O)c(F)cc(F)c3F)nn2)ccc1O   \n",
      "4  Cc1csc(-c2cnc(N[C@@H]3CCN(C)C[C@H]3C(=O)NC3CCC...   \n",
      "\n",
      "                                                mol2  \\\n",
      "0                           CC(C)NCc1cc2c(nc1O)CCCC2   \n",
      "1           O=C(Nc1nnc(-c2ccc3c(c2)OCCO3)o1)c1ccccc1   \n",
      "2   Cc1cc(C)c(C(=O)CC2(C(F)(F)C(F)F)NCCN2)c(=O)[nH]1   \n",
      "3      O=C(c1ccc(Cl)c(S(=O)(=O)N2CCCCCC2)c1)N1CCOCC1   \n",
      "4  O=C(CCc1cccs1)N1CCN(C(=O)C2CCC2)[C@H]2CS(=O)(=...   \n",
      "\n",
      "                                                rule  \n",
      "0  [C;H1&$(C([#6])[#6]),H2&$(C[#6]):1][OH1].[#7:2...  \n",
      "1  [N;$(N-[#6]):3]=[C;$(C=S):1].[N;$(N[#6]);!$(N=...  \n",
      "2  [CH0;$(C-[#6]):1]#[NH0:2].[C;A;!$(C=O):3]-[*;#...  \n",
      "3  [C$(C(=C)([CX4])([CX4])),C$([CH](=C)([CX4])),C...  \n",
      "4  [C$(C(=C)([CX4,OX2,NX3])([CX4,OX2,NX3])),C$([C...  \n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 121274\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Desired maximum number of negative pairs\n",
    "MAX_PAIRS = 1_000_000\n",
    "\n",
    "# Assume 'pattern_matching_train' is your DataFrame containing the relevant data\n",
    "# It should have columns: 'molecule', 'pattern_1', 'pattern_2', 'rule'\n",
    "\n",
    "# Group by 'rule'\n",
    "grouped_rules = pattern_matching_train.groupby('rule')\n",
    "\n",
    "# Step 1: Calculate total possible pairs and per-rule pair counts for negative pairs\n",
    "total_possible = 0\n",
    "rule_pair_counts = {}\n",
    "\n",
    "print(\"Calculating possible negative pairs per rule...\")\n",
    "for rule, group in tqdm(grouped_rules, desc=\"Calculating Pairs\"):\n",
    "    # Select molecules where both pattern_1 and pattern_2 are False\n",
    "    negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "\n",
    "    negative_molecules = negative_group['molecule'].unique()\n",
    "    num_neg = len(negative_molecules)\n",
    "\n",
    "    # The number of possible ordered pairs without self-pairs\n",
    "    num_p = num_neg * (num_neg - 1)\n",
    "    rule_pair_counts[rule] = num_p\n",
    "    total_possible += num_p\n",
    "\n",
    "print(f\"Total possible negative pairs across all rules: {total_possible:,}\")\n",
    "\n",
    "# Step 2: Determine Sampling Fraction\n",
    "if total_possible <= MAX_PAIRS:\n",
    "    print(\"Total possible pairs are within the desired maximum. Generating all pairs...\")\n",
    "    negative_pairs = []\n",
    "\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Generating All Negative Pairs\"):\n",
    "        # Select molecules where both pattern_1 and pattern_2 are False\n",
    "        negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "        negative_molecules = negative_group['molecule'].unique()\n",
    "\n",
    "        if len(negative_molecules) < 2:\n",
    "            continue  # Not enough molecules to form pairs\n",
    "\n",
    "        # Create all possible ordered pairs excluding self-pairs\n",
    "        mol1, mol2 = np.meshgrid(negative_molecules, negative_molecules)\n",
    "        mol1 = mol1.flatten()\n",
    "        mol2 = mol2.flatten()\n",
    "\n",
    "        # Exclude self-pairs\n",
    "        valid_indices = mol1 != mol2\n",
    "        mol1 = mol1[valid_indices]\n",
    "        mol2 = mol2[valid_indices]\n",
    "\n",
    "        pairs = pd.DataFrame({\n",
    "            'mol1': mol1,\n",
    "            'mol2': mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        negative_pairs.append(pairs)\n",
    "\n",
    "    # Concatenate all pairs into a single DataFrame\n",
    "    negative_pairs_df = pd.concat(negative_pairs, ignore_index=True)\n",
    "    print(f\"Generated {len(negative_pairs_df):,} negative pairs.\")\n",
    "else:\n",
    "    print(\"Total possible pairs exceed the desired maximum. Sampling required...\")\n",
    "    negative_pairs = []\n",
    "\n",
    "    # Calculate sampling fraction\n",
    "    sampling_fraction = MAX_PAIRS / total_possible\n",
    "    print(f\"Sampling fraction: {sampling_fraction:.6f}\")\n",
    "\n",
    "    # Calculate the number of pairs to sample per rule\n",
    "    sampled_pairs_per_rule = {}\n",
    "    for rule, count in rule_pair_counts.items():\n",
    "        sampled_pairs = int(count * sampling_fraction)\n",
    "        # Ensure at least one pair is sampled if possible\n",
    "        if sampled_pairs < 1 and count > 0:\n",
    "            sampled_pairs = 1\n",
    "        sampled_pairs_per_rule[rule] = sampled_pairs\n",
    "\n",
    "    # Adjust total sampled pairs if sum exceeds MAX_PAIRS\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    if total_sampled > MAX_PAIRS:\n",
    "        scaling_factor = MAX_PAIRS / total_sampled\n",
    "        for rule in sampled_pairs_per_rule:\n",
    "            sampled_pairs_per_rule[rule] = int(sampled_pairs_per_rule[rule] * scaling_factor)\n",
    "\n",
    "    # Recalculate total sampled pairs after adjustment\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    print(f\"Total sampled pairs after adjustment: {total_sampled:,}\")\n",
    "\n",
    "    # Step 3: Sample pairs per rule without mapping to unique indices\n",
    "    print(\"Sampling negative pairs per rule...\")\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Sampling Pairs\"):\n",
    "        num_to_sample = sampled_pairs_per_rule.get(rule, 0)\n",
    "        if num_to_sample == 0:\n",
    "            continue\n",
    "\n",
    "        # Select molecules where both patterns are False\n",
    "        negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "        negative_molecules = negative_group['molecule'].unique()\n",
    "        n = len(negative_molecules)\n",
    "\n",
    "        if n < 2:\n",
    "            continue  # Not enough molecules to form pairs\n",
    "\n",
    "        # Sample mol1 and mol2 with replacement\n",
    "        # Since n is large and num_to_sample is relatively small, probability of duplicates is low\n",
    "        mol1 = np.random.choice(negative_molecules, size=num_to_sample, replace=True)\n",
    "        mol2 = np.random.choice(negative_molecules, size=num_to_sample, replace=True)\n",
    "\n",
    "        # Exclude self-pairs\n",
    "        mask = mol1 != mol2\n",
    "        mol1 = mol1[mask]\n",
    "        mol2 = mol2[mask]\n",
    "\n",
    "        # If after masking, we have fewer pairs than desired, resample the missing\n",
    "        missing = num_to_sample - len(mol1)\n",
    "        while missing > 0:\n",
    "            additional_mol1 = np.random.choice(negative_molecules, size=missing, replace=True)\n",
    "            additional_mol2 = np.random.choice(negative_molecules, size=missing, replace=True)\n",
    "            additional_mask = additional_mol1 != additional_mol2\n",
    "            mol1 = np.concatenate([mol1, additional_mol1[additional_mask]])\n",
    "            mol2 = np.concatenate([mol2, additional_mol2[additional_mask]])\n",
    "            missing = num_to_sample - len(mol1)\n",
    "\n",
    "        # Create a DataFrame of sampled negative pairs\n",
    "        sampled_df = pd.DataFrame({\n",
    "            'mol1': mol1,\n",
    "            'mol2': mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        # Append to negative_pairs\n",
    "        negative_pairs.append(sampled_df)\n",
    "\n",
    "    # Concatenate all sampled pairs into a single DataFrame\n",
    "    negative_pairs_df = pd.concat(negative_pairs, ignore_index=True)\n",
    "\n",
    "    # Shuffle the DataFrame to ensure randomness\n",
    "    negative_pairs_df = negative_pairs_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "    # Limit to MAX_PAIRS if necessary\n",
    "    if len(negative_pairs_df) > MAX_PAIRS:\n",
    "        negative_pairs_df = negative_pairs_df.iloc[:MAX_PAIRS]\n",
    "\n",
    "    print(f\"Generated {len(negative_pairs_df):,} sampled negative pairs.\")\n",
    "\n",
    "# Final DataFrame: negative_pairs_df\n",
    "print(f\"Final number of negative pairs: {len(negative_pairs_df):,}\")\n",
    "\n",
    "# Display a preview\n",
    "print(negative_pairs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs_df.to_csv(\"neg_pairs_train_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating possible pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Pairs: 100%|██████████| 56/56 [00:02<00:00, 27.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible pairs across all rules: 5828573699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 121274\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Desired maximum number of positive pairs\n",
    "MAX_PAIRS = 100_000\n",
    "\n",
    "# Group by 'rule'\n",
    "grouped_rules = pattern_matching_val.groupby('rule')\n",
    "\n",
    "# Step 1: Calculate total possible pairs and per-rule pair counts\n",
    "total_possible = 0\n",
    "rule_pair_counts = {}\n",
    "\n",
    "# First pass: compute possible pairs per rule\n",
    "print(\"Calculating possible pairs per rule...\")\n",
    "for rule, group in tqdm(grouped_rules, desc=\"Calculating Pairs\"):\n",
    "    pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "    pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "    num_p = len(pattern1_molecules) * len(pattern2_molecules)\n",
    "    rule_pair_counts[rule] = num_p\n",
    "    total_possible += num_p\n",
    "\n",
    "print(f\"Total possible pairs across all rules: {total_possible}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling fraction: 0.000017\n",
      "Total sampled pairs after adjustment: 99989\n",
      "Sampling pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Pairs: 100%|██████████| 56/56 [00:01<00:00, 47.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 99989 sampled positive pairs.\n",
      "Final number of positive pairs: 99989\n",
      "                                                mol1  \\\n",
      "0  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)c(F)c1)NC...   \n",
      "1  Cc1cc(C#N)cc(C)c1Oc1nc(NC2CCN(c3c(F)cc(NS(N)(=...   \n",
      "2  C=C[C@@H]1C[C@]1(NC(=O)[C@@H]1C[C@@]2(CN1C(=O)...   \n",
      "3                    NC(CC(=O)O)c1ccccc1[N+](=O)[O-]   \n",
      "4    Cc1c(C)c2ccc(OC3CCN(Cc4ccc(C#N)cc4)CC3)cc2oc1=O   \n",
      "\n",
      "                                                mol2  \\\n",
      "0  CNC(=O)OCCc1ccc(Cl)c(CN(C(=O)[C@H]2CNCC(=O)N2c...   \n",
      "1                          NOC(c1ccccc1)c1cccc(Br)c1   \n",
      "2                        Oc1nc2nonc2nc1-c1ccc(Br)cc1   \n",
      "3  Nc1ccc(CCn2cnc3c(Nc4cccc(N)c4)nc(NC4CCC4)nc32)cc1   \n",
      "4           O=C(O)c1ccnc(-n2nc(Cc3c(F)cccc3F)cc2O)c1   \n",
      "\n",
      "                                                rule  \n",
      "0  [Cl,OH,O-:3][C$(C(=O)([CX4,c])),C$([CH](=O)):2...  \n",
      "1  [#6:1][C:2]#[#7;D1].[Cl,Br,I][#6;$([#6]~[#6]);...  \n",
      "2  [C$([CH](=C)([CX4])),C$([CH2](=C)):2]=[C$(C(=C...  \n",
      "3  [Cl,OH,O-:3][C$(C(=O)([CX4,c])),C$([CH](=O)):2...  \n",
      "4  [CH0;$(C-[#6]):1]#[NH0:2].[CH0;$(C-[#6]);R0:5]...  \n"
     ]
    }
   ],
   "source": [
    "# If total_possible is less than MAX_PAIRS, proceed without sampling\n",
    "if total_possible <= MAX_PAIRS:\n",
    "    positive_pairs = []\n",
    "\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Generating All Pairs\"):\n",
    "        pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "        pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "\n",
    "        # Create all possible pairs using cross join\n",
    "        pairs = pd.MultiIndex.from_product(\n",
    "            [pattern1_molecules, pattern2_molecules],\n",
    "            names=['mol1', 'mol2']\n",
    "        ).to_frame(index=False)\n",
    "\n",
    "        # Add 'rule' column\n",
    "        pairs['rule'] = rule\n",
    "\n",
    "        # Append to positive_pairs\n",
    "        positive_pairs.append(pairs)\n",
    "\n",
    "    # Concatenate all pairs into a single DataFrame\n",
    "    positive_pairs_df = pd.concat(positive_pairs, ignore_index=True)\n",
    "    print(f\"Generated {len(positive_pairs_df)} positive pairs.\")\n",
    "else:\n",
    "    # Need to sample pairs to limit total number to MAX_PAIRS\n",
    "    positive_pairs = []\n",
    "\n",
    "    # Calculate sampling fraction\n",
    "    sampling_fraction = MAX_PAIRS / total_possible\n",
    "    print(f\"Sampling fraction: {sampling_fraction:.6f}\")\n",
    "\n",
    "    # Calculate the number of pairs to sample per rule\n",
    "    sampled_pairs_per_rule = {}\n",
    "    for rule, count in rule_pair_counts.items():\n",
    "        sampled_pairs = int(count * sampling_fraction)\n",
    "        # Ensure at least one pair is sampled if possible\n",
    "        if sampled_pairs < 1 and count > 0:\n",
    "            sampled_pairs = 1\n",
    "        sampled_pairs_per_rule[rule] = sampled_pairs\n",
    "\n",
    "    # Adjust total sampled pairs if sum exceeds MAX_PAIRS\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    if total_sampled > MAX_PAIRS:\n",
    "        # Reduce the number of pairs proportionally\n",
    "        scaling_factor = MAX_PAIRS / total_sampled\n",
    "        for rule in sampled_pairs_per_rule:\n",
    "            sampled_pairs_per_rule[rule] = int(sampled_pairs_per_rule[rule] * scaling_factor)\n",
    "    \n",
    "    # Recalculate total sampled pairs after adjustment\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    print(f\"Total sampled pairs after adjustment: {total_sampled}\")\n",
    "\n",
    "    # Second pass: sample pairs per rule\n",
    "    print(\"Sampling pairs per rule...\")\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Sampling Pairs\"):\n",
    "        num_to_sample = sampled_pairs_per_rule.get(rule, 0)\n",
    "        if num_to_sample == 0:\n",
    "            continue\n",
    "\n",
    "        pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "        pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "\n",
    "        n1 = len(pattern1_molecules)\n",
    "        n2 = len(pattern2_molecules)\n",
    "\n",
    "        if n1 == 0 or n2 == 0:\n",
    "            continue  # No possible pairs for this rule\n",
    "\n",
    "        # If the number of possible pairs is less than or equal to num_to_sample, take all\n",
    "        if n1 * n2 <= num_to_sample:\n",
    "            sampled_mol1 = np.repeat(pattern1_molecules, n2)\n",
    "            sampled_mol2 = np.tile(pattern2_molecules, n1)\n",
    "        else:\n",
    "            # Randomly sample with replacement=False if possible\n",
    "            # To sample unique pairs without replacement, we can sample indices\n",
    "            sampled_indices_mol1 = np.random.choice(n1, size=num_to_sample, replace=True)\n",
    "            sampled_indices_mol2 = np.random.choice(n2, size=num_to_sample, replace=True)\n",
    "            sampled_mol1 = pattern1_molecules[sampled_indices_mol1]\n",
    "            sampled_mol2 = pattern2_molecules[sampled_indices_mol2]\n",
    "\n",
    "        # Create a DataFrame of sampled pairs\n",
    "        sampled_df = pd.DataFrame({\n",
    "            'molecule': sampled_mol1,\n",
    "            'paired_molecule': sampled_mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        # Append to positive_pairs\n",
    "        positive_pairs.append(sampled_df)\n",
    "\n",
    "    # Concatenate all sampled pairs into a single DataFrame\n",
    "    positive_pairs_df = pd.concat(positive_pairs, ignore_index=True)\n",
    "    # Rename columns for consistency\n",
    "    positive_pairs_df.rename(columns={'molecule': 'mol1', 'paired_molecule': 'mol2'}, inplace=True)\n",
    "    print(f\"Generated {len(positive_pairs_df)} sampled positive pairs.\")\n",
    "\n",
    "# Optional: Shuffle the positive_pairs_df\n",
    "positive_pairs_df = positive_pairs_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# Limit to MAX_PAIRS if necessary\n",
    "if len(positive_pairs_df) > MAX_PAIRS:\n",
    "    positive_pairs_df = positive_pairs_df.iloc[:MAX_PAIRS]\n",
    "\n",
    "print(f\"Final number of positive pairs: {len(positive_pairs_df)}\")\n",
    "\n",
    "# Display a preview\n",
    "print(positive_pairs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs_df.to_csv(\"pos_pairs_val_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating possible negative pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Pairs: 100%|██████████| 56/56 [00:03<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible negative pairs across all rules: 2,712,584,459,676\n",
      "Total possible pairs exceed the desired maximum. Sampling required...\n",
      "Sampling fraction: 0.000000\n",
      "Total sampled pairs after adjustment: 99,971\n",
      "Sampling negative pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Pairs: 100%|██████████| 56/56 [00:03<00:00, 15.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 99,971 sampled negative pairs.\n",
      "Final number of negative pairs: 99,971\n",
      "                                                mol1  \\\n",
      "0                  Cc1ccc(-n2nc(C)c3onc(C)c3c2=O)cc1   \n",
      "1   CCc1nc2ccc(C(=O)NCc3ccc(OC)cc3)cn2c1N(CC)CCN(C)C   \n",
      "2          CC/N=c1/cc2oc3cc(NCCCN)c4ccccc4c3nc-2cc1C   \n",
      "3  O=C(O)Cc1ccc(-c2ccccc2NC(=O)Cc2cccc(-c3ccc(O)c...   \n",
      "4                CCN1CCSc2ccc(C(=O)NCc3ccccc3Br)cc21   \n",
      "\n",
      "                                                mol2  \\\n",
      "0         Cc1nc(Cn2nc(C3CCNCC3)n(Cc3ccccc3)c2=O)sc1C   \n",
      "1  COc1cc(-c2cn(C3C(=O)NC4CCC3C4)nn2)ccc1-n1cnc(C)c1   \n",
      "2      CC(=O)N1c2ccccc2C(=O)C1N1CCN(c2cccc(Cl)c2)CC1   \n",
      "3  CC1(C)N2Cc3[nH]c4ccccc4c3C[C@H]2C(=O)N1[C@@H](...   \n",
      "4  NC(=O)c1cccc2c1CC(N(CCCc1c[nH]c3ccc(F)cc13)C1C...   \n",
      "\n",
      "                                                rule  \n",
      "0  [c;r6:1](-[NH1;$(N-[#6]):2]):[c;r6:3](-[NH2:4]...  \n",
      "1  [NH2,NH3+1:8]-[c:5]1[cH:4][c:3][c:2][c:1][c:6]...  \n",
      "2  [c:1](-[OH1;$(Oc1ccccc1):2]):[c;r6:3](-[NH2:4]...  \n",
      "3  [#6:1][C:2]#[#7;D1].[Cl,Br,I][#6;$([#6]~[#6]);...  \n",
      "4  [c;$(c1ccc(N(~O)~O)cc1):1][Cl,F].[N;$(NC);!$(N...  \n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 121274\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Desired maximum number of negative pairs\n",
    "MAX_PAIRS = 100_000\n",
    "\n",
    "# Assume 'pattern_matching_train' is your DataFrame containing the relevant data\n",
    "# It should have columns: 'molecule', 'pattern_1', 'pattern_2', 'rule'\n",
    "\n",
    "# Group by 'rule'\n",
    "grouped_rules = pattern_matching_val.groupby('rule')\n",
    "\n",
    "# Step 1: Calculate total possible pairs and per-rule pair counts for negative pairs\n",
    "total_possible = 0\n",
    "rule_pair_counts = {}\n",
    "\n",
    "print(\"Calculating possible negative pairs per rule...\")\n",
    "for rule, group in tqdm(grouped_rules, desc=\"Calculating Pairs\"):\n",
    "    # Select molecules where both pattern_1 and pattern_2 are False\n",
    "    negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "\n",
    "    negative_molecules = negative_group['molecule'].unique()\n",
    "    num_neg = len(negative_molecules)\n",
    "\n",
    "    # The number of possible ordered pairs without self-pairs\n",
    "    num_p = num_neg * (num_neg - 1)\n",
    "    rule_pair_counts[rule] = num_p\n",
    "    total_possible += num_p\n",
    "\n",
    "print(f\"Total possible negative pairs across all rules: {total_possible:,}\")\n",
    "\n",
    "# Step 2: Determine Sampling Fraction\n",
    "if total_possible <= MAX_PAIRS:\n",
    "    print(\"Total possible pairs are within the desired maximum. Generating all pairs...\")\n",
    "    negative_pairs = []\n",
    "\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Generating All Negative Pairs\"):\n",
    "        # Select molecules where both pattern_1 and pattern_2 are False\n",
    "        negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "        negative_molecules = negative_group['molecule'].unique()\n",
    "\n",
    "        if len(negative_molecules) < 2:\n",
    "            continue  # Not enough molecules to form pairs\n",
    "\n",
    "        # Create all possible ordered pairs excluding self-pairs\n",
    "        mol1, mol2 = np.meshgrid(negative_molecules, negative_molecules)\n",
    "        mol1 = mol1.flatten()\n",
    "        mol2 = mol2.flatten()\n",
    "\n",
    "        # Exclude self-pairs\n",
    "        valid_indices = mol1 != mol2\n",
    "        mol1 = mol1[valid_indices]\n",
    "        mol2 = mol2[valid_indices]\n",
    "\n",
    "        pairs = pd.DataFrame({\n",
    "            'mol1': mol1,\n",
    "            'mol2': mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        negative_pairs.append(pairs)\n",
    "\n",
    "    # Concatenate all pairs into a single DataFrame\n",
    "    negative_pairs_df = pd.concat(negative_pairs, ignore_index=True)\n",
    "    print(f\"Generated {len(negative_pairs_df):,} negative pairs.\")\n",
    "else:\n",
    "    print(\"Total possible pairs exceed the desired maximum. Sampling required...\")\n",
    "    negative_pairs = []\n",
    "\n",
    "    # Calculate sampling fraction\n",
    "    sampling_fraction = MAX_PAIRS / total_possible\n",
    "    print(f\"Sampling fraction: {sampling_fraction:.6f}\")\n",
    "\n",
    "    # Calculate the number of pairs to sample per rule\n",
    "    sampled_pairs_per_rule = {}\n",
    "    for rule, count in rule_pair_counts.items():\n",
    "        sampled_pairs = int(count * sampling_fraction)\n",
    "        # Ensure at least one pair is sampled if possible\n",
    "        if sampled_pairs < 1 and count > 0:\n",
    "            sampled_pairs = 1\n",
    "        sampled_pairs_per_rule[rule] = sampled_pairs\n",
    "\n",
    "    # Adjust total sampled pairs if sum exceeds MAX_PAIRS\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    if total_sampled > MAX_PAIRS:\n",
    "        scaling_factor = MAX_PAIRS / total_sampled\n",
    "        for rule in sampled_pairs_per_rule:\n",
    "            sampled_pairs_per_rule[rule] = int(sampled_pairs_per_rule[rule] * scaling_factor)\n",
    "\n",
    "    # Recalculate total sampled pairs after adjustment\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    print(f\"Total sampled pairs after adjustment: {total_sampled:,}\")\n",
    "\n",
    "    # Step 3: Sample pairs per rule without mapping to unique indices\n",
    "    print(\"Sampling negative pairs per rule...\")\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Sampling Pairs\"):\n",
    "        num_to_sample = sampled_pairs_per_rule.get(rule, 0)\n",
    "        if num_to_sample == 0:\n",
    "            continue\n",
    "\n",
    "        # Select molecules where both patterns are False\n",
    "        negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "        negative_molecules = negative_group['molecule'].unique()\n",
    "        n = len(negative_molecules)\n",
    "\n",
    "        if n < 2:\n",
    "            continue  # Not enough molecules to form pairs\n",
    "\n",
    "        # Sample mol1 and mol2 with replacement\n",
    "        # Since n is large and num_to_sample is relatively small, probability of duplicates is low\n",
    "        mol1 = np.random.choice(negative_molecules, size=num_to_sample, replace=True)\n",
    "        mol2 = np.random.choice(negative_molecules, size=num_to_sample, replace=True)\n",
    "\n",
    "        # Exclude self-pairs\n",
    "        mask = mol1 != mol2\n",
    "        mol1 = mol1[mask]\n",
    "        mol2 = mol2[mask]\n",
    "\n",
    "        # If after masking, we have fewer pairs than desired, resample the missing\n",
    "        missing = num_to_sample - len(mol1)\n",
    "        while missing > 0:\n",
    "            additional_mol1 = np.random.choice(negative_molecules, size=missing, replace=True)\n",
    "            additional_mol2 = np.random.choice(negative_molecules, size=missing, replace=True)\n",
    "            additional_mask = additional_mol1 != additional_mol2\n",
    "            mol1 = np.concatenate([mol1, additional_mol1[additional_mask]])\n",
    "            mol2 = np.concatenate([mol2, additional_mol2[additional_mask]])\n",
    "            missing = num_to_sample - len(mol1)\n",
    "\n",
    "        # Create a DataFrame of sampled negative pairs\n",
    "        sampled_df = pd.DataFrame({\n",
    "            'mol1': mol1,\n",
    "            'mol2': mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        # Append to negative_pairs\n",
    "        negative_pairs.append(sampled_df)\n",
    "\n",
    "    # Concatenate all sampled pairs into a single DataFrame\n",
    "    negative_pairs_df = pd.concat(negative_pairs, ignore_index=True)\n",
    "\n",
    "    # Shuffle the DataFrame to ensure randomness\n",
    "    negative_pairs_df = negative_pairs_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "    # Limit to MAX_PAIRS if necessary\n",
    "    if len(negative_pairs_df) > MAX_PAIRS:\n",
    "        negative_pairs_df = negative_pairs_df.iloc[:MAX_PAIRS]\n",
    "\n",
    "    print(f\"Generated {len(negative_pairs_df):,} sampled negative pairs.\")\n",
    "\n",
    "# Final DataFrame: negative_pairs_df\n",
    "print(f\"Final number of negative pairs: {len(negative_pairs_df):,}\")\n",
    "\n",
    "# Display a preview\n",
    "print(negative_pairs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs_df.to_csv(\"neg_pairs_val_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating possible pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Pairs: 100%|██████████| 56/56 [00:01<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible pairs across all rules: 23004542090\n",
      "Sampling fraction: 0.000004\n",
      "Total sampled pairs after adjustment: 99993\n",
      "Sampling pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Pairs: 100%|██████████| 56/56 [00:01<00:00, 29.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 99993 sampled positive pairs.\n",
      "Final number of positive pairs: 99993\n",
      "                                                mol1  \\\n",
      "0          Cc1cc(NCc2cccc(Cl)c2Cl)c2cccc(C(=O)O)c2n1   \n",
      "1  Cc1ccc(C(=O)N2CC(c3ccc(C#N)cc3)C2)cc1-c1[nH]c(...   \n",
      "2  CC1(C)C=C2[C@H]3CC[C@@H]4[C@@]5(C)CCC(=O)C(C)(...   \n",
      "3          CN(C)/C=N/[C@@H](C(=O)[O-])c1ccccc1.[Na+]   \n",
      "4      C[C@@H]1CCCN1CCc1ccc2nc(-c3ccc(C#N)cc3)ccc2c1   \n",
      "\n",
      "                                                mol2  \\\n",
      "0  COc1cc(-c2ccc3ncc(C(C)=O)c(N[C@@H]4CCC[C@@H](C...   \n",
      "1                      COc1ccc2c(C)c(Br)c(=O)oc2c1Br   \n",
      "2  C=CCO[C@@H]1[C@H](O)[C@H](Oc2ccc(I)cc2)O[C@@H]...   \n",
      "3  CC(C)CCC[C@@H](C)CCC[C@@H](C)CCC[C@@H](C)CCOC[...   \n",
      "4            CCOC(=O)c1cc(-c2ccc(Cl)cc2)nc2onc(C)c12   \n",
      "\n",
      "                                                rule  \n",
      "0  [Cl,OH,O-:3][C$(C(=O)([CX4,c])),C$([CH](=O)):2...  \n",
      "1  [#6:1][C:2]#[#7;D1].[Cl,Br,I][#6;$([#6]~[#6]);...  \n",
      "2  [C$([CH](=C)([CX4])),C$([CH2](=C)):2]=[C$(C(=C...  \n",
      "3  [OH,O-]-[C$(C(=O)(O)([CX4,c])):2]=[O:3].[OH:8]...  \n",
      "4  [CH0;$(C-[#6]):1]#[NH0:2].[CH0;$(C-[#6]);R0:5]...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 121274\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Desired maximum number of positive pairs\n",
    "MAX_PAIRS = 100_000\n",
    "\n",
    "# Group by 'rule'\n",
    "grouped_rules = pattern_matching_test.groupby('rule')\n",
    "\n",
    "# Step 1: Calculate total possible pairs and per-rule pair counts\n",
    "total_possible = 0\n",
    "rule_pair_counts = {}\n",
    "\n",
    "# First pass: compute possible pairs per rule\n",
    "print(\"Calculating possible pairs per rule...\")\n",
    "for rule, group in tqdm(grouped_rules, desc=\"Calculating Pairs\"):\n",
    "    pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "    pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "    num_p = len(pattern1_molecules) * len(pattern2_molecules)\n",
    "    rule_pair_counts[rule] = num_p\n",
    "    total_possible += num_p\n",
    "\n",
    "print(f\"Total possible pairs across all rules: {total_possible}\")\n",
    "\n",
    "# If total_possible is less than MAX_PAIRS, proceed without sampling\n",
    "if total_possible <= MAX_PAIRS:\n",
    "    positive_pairs = []\n",
    "\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Generating All Pairs\"):\n",
    "        pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "        pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "\n",
    "        # Create all possible pairs using cross join\n",
    "        pairs = pd.MultiIndex.from_product(\n",
    "            [pattern1_molecules, pattern2_molecules],\n",
    "            names=['mol1', 'mol2']\n",
    "        ).to_frame(index=False)\n",
    "\n",
    "        # Add 'rule' column\n",
    "        pairs['rule'] = rule\n",
    "\n",
    "        # Append to positive_pairs\n",
    "        positive_pairs.append(pairs)\n",
    "\n",
    "    # Concatenate all pairs into a single DataFrame\n",
    "    positive_pairs_df = pd.concat(positive_pairs, ignore_index=True)\n",
    "    print(f\"Generated {len(positive_pairs_df)} positive pairs.\")\n",
    "else:\n",
    "    # Need to sample pairs to limit total number to MAX_PAIRS\n",
    "    positive_pairs = []\n",
    "\n",
    "    # Calculate sampling fraction\n",
    "    sampling_fraction = MAX_PAIRS / total_possible\n",
    "    print(f\"Sampling fraction: {sampling_fraction:.6f}\")\n",
    "\n",
    "    # Calculate the number of pairs to sample per rule\n",
    "    sampled_pairs_per_rule = {}\n",
    "    for rule, count in rule_pair_counts.items():\n",
    "        sampled_pairs = int(count * sampling_fraction)\n",
    "        # Ensure at least one pair is sampled if possible\n",
    "        if sampled_pairs < 1 and count > 0:\n",
    "            sampled_pairs = 1\n",
    "        sampled_pairs_per_rule[rule] = sampled_pairs\n",
    "\n",
    "    # Adjust total sampled pairs if sum exceeds MAX_PAIRS\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    if total_sampled > MAX_PAIRS:\n",
    "        # Reduce the number of pairs proportionally\n",
    "        scaling_factor = MAX_PAIRS / total_sampled\n",
    "        for rule in sampled_pairs_per_rule:\n",
    "            sampled_pairs_per_rule[rule] = int(sampled_pairs_per_rule[rule] * scaling_factor)\n",
    "    \n",
    "    # Recalculate total sampled pairs after adjustment\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    print(f\"Total sampled pairs after adjustment: {total_sampled}\")\n",
    "\n",
    "    # Second pass: sample pairs per rule\n",
    "    print(\"Sampling pairs per rule...\")\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Sampling Pairs\"):\n",
    "        num_to_sample = sampled_pairs_per_rule.get(rule, 0)\n",
    "        if num_to_sample == 0:\n",
    "            continue\n",
    "\n",
    "        pattern1_molecules = group[group['pattern_1']]['molecule'].unique()\n",
    "        pattern2_molecules = group[group['pattern_2']]['molecule'].unique()\n",
    "\n",
    "        n1 = len(pattern1_molecules)\n",
    "        n2 = len(pattern2_molecules)\n",
    "\n",
    "        if n1 == 0 or n2 == 0:\n",
    "            continue  # No possible pairs for this rule\n",
    "\n",
    "        # If the number of possible pairs is less than or equal to num_to_sample, take all\n",
    "        if n1 * n2 <= num_to_sample:\n",
    "            sampled_mol1 = np.repeat(pattern1_molecules, n2)\n",
    "            sampled_mol2 = np.tile(pattern2_molecules, n1)\n",
    "        else:\n",
    "            # Randomly sample with replacement=False if possible\n",
    "            # To sample unique pairs without replacement, we can sample indices\n",
    "            sampled_indices_mol1 = np.random.choice(n1, size=num_to_sample, replace=True)\n",
    "            sampled_indices_mol2 = np.random.choice(n2, size=num_to_sample, replace=True)\n",
    "            sampled_mol1 = pattern1_molecules[sampled_indices_mol1]\n",
    "            sampled_mol2 = pattern2_molecules[sampled_indices_mol2]\n",
    "\n",
    "        # Create a DataFrame of sampled pairs\n",
    "        sampled_df = pd.DataFrame({\n",
    "            'molecule': sampled_mol1,\n",
    "            'paired_molecule': sampled_mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        # Append to positive_pairs\n",
    "        positive_pairs.append(sampled_df)\n",
    "\n",
    "    # Concatenate all sampled pairs into a single DataFrame\n",
    "    positive_pairs_df = pd.concat(positive_pairs, ignore_index=True)\n",
    "    # Rename columns for consistency\n",
    "    positive_pairs_df.rename(columns={'molecule': 'mol1', 'paired_molecule': 'mol2'}, inplace=True)\n",
    "    print(f\"Generated {len(positive_pairs_df)} sampled positive pairs.\")\n",
    "\n",
    "# Optional: Shuffle the positive_pairs_df\n",
    "positive_pairs_df = positive_pairs_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# Limit to MAX_PAIRS if necessary\n",
    "if len(positive_pairs_df) > MAX_PAIRS:\n",
    "    positive_pairs_df = positive_pairs_df.iloc[:MAX_PAIRS]\n",
    "\n",
    "print(f\"Final number of positive pairs: {len(positive_pairs_df)}\")\n",
    "\n",
    "# Display a preview\n",
    "print(positive_pairs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs_df.to_csv(\"pos_pairs_test_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating possible negative pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Pairs: 100%|██████████| 56/56 [00:07<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible negative pairs across all rules: 10,862,728,260,242\n",
      "Total possible pairs exceed the desired maximum. Sampling required...\n",
      "Sampling fraction: 0.000000\n",
      "Total sampled pairs after adjustment: 99,975\n",
      "Sampling negative pairs per rule...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Pairs: 100%|██████████| 56/56 [00:06<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 99,975 sampled negative pairs.\n",
      "Final number of negative pairs: 99,975\n",
      "                                                mol1  \\\n",
      "0  O=C(NS(=O)(=O)c1nc2ccccc2s1)c1ccc(N2CCN(Cc3ccc...   \n",
      "1                COc1ccc(NC(=O)c2ccc3c(c2)OCO3)cc1Cl   \n",
      "2                     CCn1c2ccccc2c2cc(CC(N)=O)ccc21   \n",
      "3  CCOC(=O)C1=NN(c2ccc(F)cc2)C2=NC(C)=C(C(=O)OC)C...   \n",
      "4                       N[C@H]1C[C@@H]1c1ccc(Br)cc1F   \n",
      "\n",
      "                                                mol2  \\\n",
      "0          CCOCc1nc2c(c(NCCNC(C)=O)n1)CCN(C(C)=O)CC2   \n",
      "1               COc1ccc(C(=O)C(Cn2ccnc2)Cn2ccnc2)cc1   \n",
      "2  COc1ccc(C[C@H](NC(=O)[C@@H]2CSCC[C@H](NC(C)=O)...   \n",
      "3  CC(C)=CC[C@]12C[C@H]3C[C@H]4C(C)(C)O[C@@H](C=C...   \n",
      "4  CCCC1N(CC2CCCCC2)C(=O)OC12CCN(C1CCN(C(=O)c3c(C...   \n",
      "\n",
      "                                                rule  \n",
      "0  [Cl:5][S$(S(=O)(=O)(Cl)([CX4])):2](=[O:3])=[O:...  \n",
      "1  [S;$(S(=O)(=O)[C,N]):1][Cl].[N;$(NC);!$(N=*);!...  \n",
      "2  [OH:7]-[c:6]1[cH:1][c:2][c:3][c:4][c:5]1.[O$(O...  \n",
      "3  [#6:1][C:2]#[#7;D1].[Cl,Br,I][#6;$([#6]~[#6]);...  \n",
      "4  [I:1][C$(C(I)([CX4,c])([CX4,c])([CX4,c])),C$([...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 121274\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Desired maximum number of negative pairs\n",
    "MAX_PAIRS = 100_000\n",
    "\n",
    "# Assume 'pattern_matching_train' is your DataFrame containing the relevant data\n",
    "# It should have columns: 'molecule', 'pattern_1', 'pattern_2', 'rule'\n",
    "\n",
    "# Group by 'rule'\n",
    "grouped_rules = pattern_matching_test.groupby('rule')\n",
    "\n",
    "# Step 1: Calculate total possible pairs and per-rule pair counts for negative pairs\n",
    "total_possible = 0\n",
    "rule_pair_counts = {}\n",
    "\n",
    "print(\"Calculating possible negative pairs per rule...\")\n",
    "for rule, group in tqdm(grouped_rules, desc=\"Calculating Pairs\"):\n",
    "    # Select molecules where both pattern_1 and pattern_2 are False\n",
    "    negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "\n",
    "    negative_molecules = negative_group['molecule'].unique()\n",
    "    num_neg = len(negative_molecules)\n",
    "\n",
    "    # The number of possible ordered pairs without self-pairs\n",
    "    num_p = num_neg * (num_neg - 1)\n",
    "    rule_pair_counts[rule] = num_p\n",
    "    total_possible += num_p\n",
    "\n",
    "print(f\"Total possible negative pairs across all rules: {total_possible:,}\")\n",
    "\n",
    "# Step 2: Determine Sampling Fraction\n",
    "if total_possible <= MAX_PAIRS:\n",
    "    print(\"Total possible pairs are within the desired maximum. Generating all pairs...\")\n",
    "    negative_pairs = []\n",
    "\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Generating All Negative Pairs\"):\n",
    "        # Select molecules where both pattern_1 and pattern_2 are False\n",
    "        negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "        negative_molecules = negative_group['molecule'].unique()\n",
    "\n",
    "        if len(negative_molecules) < 2:\n",
    "            continue  # Not enough molecules to form pairs\n",
    "\n",
    "        # Create all possible ordered pairs excluding self-pairs\n",
    "        mol1, mol2 = np.meshgrid(negative_molecules, negative_molecules)\n",
    "        mol1 = mol1.flatten()\n",
    "        mol2 = mol2.flatten()\n",
    "\n",
    "        # Exclude self-pairs\n",
    "        valid_indices = mol1 != mol2\n",
    "        mol1 = mol1[valid_indices]\n",
    "        mol2 = mol2[valid_indices]\n",
    "\n",
    "        pairs = pd.DataFrame({\n",
    "            'mol1': mol1,\n",
    "            'mol2': mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        negative_pairs.append(pairs)\n",
    "\n",
    "    # Concatenate all pairs into a single DataFrame\n",
    "    negative_pairs_df = pd.concat(negative_pairs, ignore_index=True)\n",
    "    print(f\"Generated {len(negative_pairs_df):,} negative pairs.\")\n",
    "else:\n",
    "    print(\"Total possible pairs exceed the desired maximum. Sampling required...\")\n",
    "    negative_pairs = []\n",
    "\n",
    "    # Calculate sampling fraction\n",
    "    sampling_fraction = MAX_PAIRS / total_possible\n",
    "    print(f\"Sampling fraction: {sampling_fraction:.6f}\")\n",
    "\n",
    "    # Calculate the number of pairs to sample per rule\n",
    "    sampled_pairs_per_rule = {}\n",
    "    for rule, count in rule_pair_counts.items():\n",
    "        sampled_pairs = int(count * sampling_fraction)\n",
    "        # Ensure at least one pair is sampled if possible\n",
    "        if sampled_pairs < 1 and count > 0:\n",
    "            sampled_pairs = 1\n",
    "        sampled_pairs_per_rule[rule] = sampled_pairs\n",
    "\n",
    "    # Adjust total sampled pairs if sum exceeds MAX_PAIRS\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    if total_sampled > MAX_PAIRS:\n",
    "        scaling_factor = MAX_PAIRS / total_sampled\n",
    "        for rule in sampled_pairs_per_rule:\n",
    "            sampled_pairs_per_rule[rule] = int(sampled_pairs_per_rule[rule] * scaling_factor)\n",
    "\n",
    "    # Recalculate total sampled pairs after adjustment\n",
    "    total_sampled = sum(sampled_pairs_per_rule.values())\n",
    "    print(f\"Total sampled pairs after adjustment: {total_sampled:,}\")\n",
    "\n",
    "    # Step 3: Sample pairs per rule without mapping to unique indices\n",
    "    print(\"Sampling negative pairs per rule...\")\n",
    "    for rule, group in tqdm(grouped_rules, desc=\"Sampling Pairs\"):\n",
    "        num_to_sample = sampled_pairs_per_rule.get(rule, 0)\n",
    "        if num_to_sample == 0:\n",
    "            continue\n",
    "\n",
    "        # Select molecules where both patterns are False\n",
    "        negative_group = group[(~group['pattern_1']) & (~group['pattern_2'])]\n",
    "        negative_molecules = negative_group['molecule'].unique()\n",
    "        n = len(negative_molecules)\n",
    "\n",
    "        if n < 2:\n",
    "            continue  # Not enough molecules to form pairs\n",
    "\n",
    "        # Sample mol1 and mol2 with replacement\n",
    "        # Since n is large and num_to_sample is relatively small, probability of duplicates is low\n",
    "        mol1 = np.random.choice(negative_molecules, size=num_to_sample, replace=True)\n",
    "        mol2 = np.random.choice(negative_molecules, size=num_to_sample, replace=True)\n",
    "\n",
    "        # Exclude self-pairs\n",
    "        mask = mol1 != mol2\n",
    "        mol1 = mol1[mask]\n",
    "        mol2 = mol2[mask]\n",
    "\n",
    "        # If after masking, we have fewer pairs than desired, resample the missing\n",
    "        missing = num_to_sample - len(mol1)\n",
    "        while missing > 0:\n",
    "            additional_mol1 = np.random.choice(negative_molecules, size=missing, replace=True)\n",
    "            additional_mol2 = np.random.choice(negative_molecules, size=missing, replace=True)\n",
    "            additional_mask = additional_mol1 != additional_mol2\n",
    "            mol1 = np.concatenate([mol1, additional_mol1[additional_mask]])\n",
    "            mol2 = np.concatenate([mol2, additional_mol2[additional_mask]])\n",
    "            missing = num_to_sample - len(mol1)\n",
    "\n",
    "        # Create a DataFrame of sampled negative pairs\n",
    "        sampled_df = pd.DataFrame({\n",
    "            'mol1': mol1,\n",
    "            'mol2': mol2,\n",
    "            'rule': rule\n",
    "        })\n",
    "\n",
    "        # Append to negative_pairs\n",
    "        negative_pairs.append(sampled_df)\n",
    "\n",
    "    # Concatenate all sampled pairs into a single DataFrame\n",
    "    negative_pairs_df = pd.concat(negative_pairs, ignore_index=True)\n",
    "\n",
    "    # Shuffle the DataFrame to ensure randomness\n",
    "    negative_pairs_df = negative_pairs_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "    # Limit to MAX_PAIRS if necessary\n",
    "    if len(negative_pairs_df) > MAX_PAIRS:\n",
    "        negative_pairs_df = negative_pairs_df.iloc[:MAX_PAIRS]\n",
    "\n",
    "    print(f\"Generated {len(negative_pairs_df):,} sampled negative pairs.\")\n",
    "\n",
    "# Final DataFrame: negative_pairs_df\n",
    "print(f\"Final number of negative pairs: {len(negative_pairs_df):,}\")\n",
    "\n",
    "# Display a preview\n",
    "print(negative_pairs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pairs_df.to_csv(\"neg_pairs_test_new.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
